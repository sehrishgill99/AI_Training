{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cb3454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Laptop wala\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 1360 files belonging to 15 classes.\n",
      "Using 1088 files for training.\n",
      "Found 1360 files belonging to 15 classes.\n",
      "Using 272 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')  # Suppresses warnings, shows only errors\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "\n",
    "data_dir = r'C:\\Users\\Laptop wala\\Desktop\\AI\\week6\\17FlowerOxfordDataset'\n",
    "\n",
    "batch_size = 32\n",
    "img_size = (128, 128)\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31bd1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    layers.RandomContrast(0.1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08c18da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Rescaling(1./255, input_shape=(128, 128, 3)),\n",
    "    \n",
    "    layers.Conv2D(16, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a7e6e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "34/34 [==============================] - 11s 231ms/step - loss: 2.5988 - accuracy: 0.1572 - val_loss: 2.2184 - val_accuracy: 0.3088\n",
      "Epoch 2/10\n",
      "34/34 [==============================] - 8s 224ms/step - loss: 2.2382 - accuracy: 0.2721 - val_loss: 1.8866 - val_accuracy: 0.4375\n",
      "Epoch 3/10\n",
      "34/34 [==============================] - 8s 223ms/step - loss: 1.9530 - accuracy: 0.3447 - val_loss: 1.6533 - val_accuracy: 0.4963\n",
      "Epoch 4/10\n",
      "34/34 [==============================] - 8s 239ms/step - loss: 1.6596 - accuracy: 0.4384 - val_loss: 1.3884 - val_accuracy: 0.5699\n",
      "Epoch 5/10\n",
      "34/34 [==============================] - 8s 229ms/step - loss: 1.3709 - accuracy: 0.5662 - val_loss: 1.2668 - val_accuracy: 0.5699\n",
      "Epoch 6/10\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 1.2137 - accuracy: 0.5901 - val_loss: 1.1834 - val_accuracy: 0.6471\n",
      "Epoch 7/10\n",
      "34/34 [==============================] - 8s 229ms/step - loss: 0.9872 - accuracy: 0.6838 - val_loss: 1.1344 - val_accuracy: 0.6434\n",
      "Epoch 8/10\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 0.9367 - accuracy: 0.6811 - val_loss: 1.1455 - val_accuracy: 0.6066\n",
      "Epoch 9/10\n",
      "34/34 [==============================] - 8s 227ms/step - loss: 0.7481 - accuracy: 0.7426 - val_loss: 1.2621 - val_accuracy: 0.5846\n",
      "Epoch 10/10\n",
      "34/34 [==============================] - 8s 230ms/step - loss: 0.6016 - accuracy: 0.8033 - val_loss: 1.1674 - val_accuracy: 0.6397\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de563d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(128, 128, 3),\n",
    "                                                include_top=False,\n",
    "                                                weights='imagenet')\n",
    "base_model.trainable = False  # Freeze it\n",
    "\n",
    "model = models.Sequential([\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(len(class_names), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a77712c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.dense.Dense at 0x1c7ad513850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41833482",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=3, restore_best_weights=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31d2c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe9fcf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2790324844.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Laptop wala\\AppData\\Local\\Temp\\ipykernel_10956\\2790324844.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    metrics=['accuracy']\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy'\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c418e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "34/34 [==============================] - 29s 520ms/step - loss: 1.7934 - accuracy: 0.4439 - val_loss: 0.7795 - val_accuracy: 0.8015\n",
      "Epoch 2/30\n",
      "34/34 [==============================] - 18s 517ms/step - loss: 0.7834 - accuracy: 0.7610 - val_loss: 0.4743 - val_accuracy: 0.8676\n",
      "Epoch 3/30\n",
      "34/34 [==============================] - 16s 474ms/step - loss: 0.5245 - accuracy: 0.8419 - val_loss: 0.3599 - val_accuracy: 0.8934\n",
      "Epoch 4/30\n",
      "34/34 [==============================] - 16s 456ms/step - loss: 0.4280 - accuracy: 0.8704 - val_loss: 0.3106 - val_accuracy: 0.8934\n",
      "Epoch 5/30\n",
      "34/34 [==============================] - 15s 445ms/step - loss: 0.3525 - accuracy: 0.8925 - val_loss: 0.3224 - val_accuracy: 0.9044\n",
      "Epoch 6/30\n",
      "34/34 [==============================] - 16s 451ms/step - loss: 0.3131 - accuracy: 0.9081 - val_loss: 0.3404 - val_accuracy: 0.9154\n",
      "Epoch 7/30\n",
      "34/34 [==============================] - 16s 463ms/step - loss: 0.2505 - accuracy: 0.9256 - val_loss: 0.2702 - val_accuracy: 0.9228\n",
      "Epoch 8/30\n",
      "34/34 [==============================] - 16s 453ms/step - loss: 0.2025 - accuracy: 0.9329 - val_loss: 0.3310 - val_accuracy: 0.9007\n",
      "Epoch 9/30\n",
      "34/34 [==============================] - 15s 427ms/step - loss: 0.2039 - accuracy: 0.9412 - val_loss: 0.2912 - val_accuracy: 0.9154\n",
      "Epoch 10/30\n",
      "34/34 [==============================] - 15s 422ms/step - loss: 0.1778 - accuracy: 0.9421 - val_loss: 0.3005 - val_accuracy: 0.9007\n",
      "Epoch 11/30\n",
      "34/34 [==============================] - 15s 432ms/step - loss: 0.1585 - accuracy: 0.9449 - val_loss: 0.2588 - val_accuracy: 0.9191\n",
      "Epoch 12/30\n",
      "34/34 [==============================] - 17s 501ms/step - loss: 0.1568 - accuracy: 0.9458 - val_loss: 0.2707 - val_accuracy: 0.9118\n",
      "Epoch 13/30\n",
      "34/34 [==============================] - 16s 449ms/step - loss: 0.1539 - accuracy: 0.9522 - val_loss: 0.3091 - val_accuracy: 0.9118\n",
      "Epoch 14/30\n",
      "34/34 [==============================] - 15s 428ms/step - loss: 0.1258 - accuracy: 0.9632 - val_loss: 0.2595 - val_accuracy: 0.9265\n",
      "Epoch 15/30\n",
      "34/34 [==============================] - 15s 423ms/step - loss: 0.1098 - accuracy: 0.9651 - val_loss: 0.2927 - val_accuracy: 0.9154\n",
      "Epoch 16/30\n",
      "34/34 [==============================] - 15s 430ms/step - loss: 0.0881 - accuracy: 0.9752 - val_loss: 0.2909 - val_accuracy: 0.9191\n",
      "Epoch 17/30\n",
      "34/34 [==============================] - 15s 446ms/step - loss: 0.1039 - accuracy: 0.9678 - val_loss: 0.3087 - val_accuracy: 0.9081\n",
      "Epoch 18/30\n",
      "34/34 [==============================] - 15s 432ms/step - loss: 0.1121 - accuracy: 0.9688 - val_loss: 0.3089 - val_accuracy: 0.9081\n",
      "Epoch 19/30\n",
      "34/34 [==============================] - 15s 434ms/step - loss: 0.0812 - accuracy: 0.9798 - val_loss: 0.2477 - val_accuracy: 0.9338\n",
      "Epoch 20/30\n",
      "34/34 [==============================] - 15s 427ms/step - loss: 0.0597 - accuracy: 0.9844 - val_loss: 0.2667 - val_accuracy: 0.9228\n",
      "Epoch 21/30\n",
      "34/34 [==============================] - 15s 427ms/step - loss: 0.0729 - accuracy: 0.9770 - val_loss: 0.2698 - val_accuracy: 0.9265\n",
      "Epoch 22/30\n",
      "34/34 [==============================] - 16s 476ms/step - loss: 0.0715 - accuracy: 0.9798 - val_loss: 0.2547 - val_accuracy: 0.9301\n",
      "Epoch 23/30\n",
      "34/34 [==============================] - 18s 513ms/step - loss: 0.0746 - accuracy: 0.9724 - val_loss: 0.2727 - val_accuracy: 0.9191\n",
      "Epoch 24/30\n",
      "34/34 [==============================] - 17s 480ms/step - loss: 0.0686 - accuracy: 0.9733 - val_loss: 0.2870 - val_accuracy: 0.9081\n",
      "Epoch 25/30\n",
      "34/34 [==============================] - 15s 435ms/step - loss: 0.0710 - accuracy: 0.9844 - val_loss: 0.2632 - val_accuracy: 0.9265\n",
      "Epoch 26/30\n",
      "34/34 [==============================] - 16s 448ms/step - loss: 0.0696 - accuracy: 0.9807 - val_loss: 0.2562 - val_accuracy: 0.9338\n",
      "Epoch 27/30\n",
      "34/34 [==============================] - 17s 479ms/step - loss: 0.0591 - accuracy: 0.9825 - val_loss: 0.2527 - val_accuracy: 0.9338\n",
      "Epoch 28/30\n",
      "34/34 [==============================] - 15s 422ms/step - loss: 0.0656 - accuracy: 0.9789 - val_loss: 0.2816 - val_accuracy: 0.9265\n",
      "Epoch 29/30\n",
      "34/34 [==============================] - 15s 431ms/step - loss: 0.0555 - accuracy: 0.9853 - val_loss: 0.2448 - val_accuracy: 0.9375\n",
      "Epoch 30/30\n",
      "34/34 [==============================] - 15s 425ms/step - loss: 0.0493 - accuracy: 0.9835 - val_loss: 0.2677 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4b9285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
