{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e7a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (3.7)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  rather than 'sklearn' for pip commands.\n",
      "  \n",
      "  Here is how to fix this error in the main use cases:\n",
      "  - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "    (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  - if the 'sklearn' package is used by one of your dependencies,\n",
      "    it would be great if you take some time to track which package uses\n",
      "    'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  - as a last resort, set the environment variable\n",
      "    SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \n",
      "  More information is available at\n",
      "  https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c186b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from scikit-learn) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\laptop wala\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Laptop wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install nltk \n",
    "!pip install scikit-learn\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07d3e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cf0ac18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f5c645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['review','sentiment'])    #remove the row that contains null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96b7fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9768030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with mebr br the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordbr br it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awaybr br i would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sample_review = df.iloc[0]['review']   #to get the first row\n",
    "\n",
    "sample_review = sample_review.lower()\n",
    "\n",
    "#remove the HTML tags      resub function\n",
    "sample_review=re.sub(r'<,*?>','',sample_review)             #remove special characters          \n",
    "sample_review=re.sub(r'[^a-zA-Z0-9\\s]','',sample_review)    # remove thesea-z A-Z and 0-9 numbers\n",
    "\n",
    "print(sample_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7805533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentences tokenization(haar word ke against apne number yeh word assign krna hai)\n",
    "\n",
    "#corpus--documentation,count the total number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2568ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one of the other reviewers has mentioned that after watching just 1 oz episode youll be hooked they are right as this is exactly what happened with mebr br the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the wordbr br it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to manyaryans muslims gangstas latinos christians italians irish and moreso scuffles death stares dodgy dealings and shady agreements are never far awaybr br i would say the main appeal of the show is due to the fact that it goes where other shows wouldnt dare forget pretty pictures painted for mainstream audiences forget charm forget romanceoz doesnt mess around the first episode i ever saw struck me as so nasty it was surreal i couldnt say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards wholl be sold out for a nickel inmates wholl kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewingthats if you can get in touch with your darker side']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "#sample_review = df.iloc[0]['review']\n",
    "sentences = sent_tokenize(sample_review)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a044080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked.\",\n",
       " 'They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO.',\n",
       " 'Trust me, this is not a show for the faint hearted or timid.',\n",
       " 'This show pulls no punches with regards to drugs, sex or violence.',\n",
       " 'Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary.',\n",
       " 'It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda.',\n",
       " \"Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare.\",\n",
       " \"Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around.\",\n",
       " \"The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence.\",\n",
       " \"Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt_tab')\n",
    "sample_review = df.iloc[0]['review']\n",
    "sentences = sent_tokenize(sample_review)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a6f97b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'Oz',\n",
       " 'episode',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'hooked',\n",
       " '.',\n",
       " 'They',\n",
       " 'are',\n",
       " 'right',\n",
       " ',',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'The',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'Oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence',\n",
       " ',',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'GO',\n",
       " '.',\n",
       " 'Trust',\n",
       " 'me',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid',\n",
       " '.',\n",
       " 'This',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs',\n",
       " ',',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence',\n",
       " '.',\n",
       " 'Its',\n",
       " 'is',\n",
       " 'hardcore',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'It',\n",
       " 'is',\n",
       " 'called',\n",
       " 'OZ',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Oswald',\n",
       " 'Maximum',\n",
       " 'Security',\n",
       " 'State',\n",
       " 'Penitentary',\n",
       " '.',\n",
       " 'It',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'Emerald',\n",
       " 'City',\n",
       " ',',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards',\n",
       " ',',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " '.',\n",
       " 'Em',\n",
       " 'City',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many',\n",
       " '..',\n",
       " 'Aryans',\n",
       " ',',\n",
       " 'Muslims',\n",
       " ',',\n",
       " 'gangstas',\n",
       " ',',\n",
       " 'Latinos',\n",
       " ',',\n",
       " 'Christians',\n",
       " ',',\n",
       " 'Italians',\n",
       " ',',\n",
       " 'Irish',\n",
       " 'and',\n",
       " 'more',\n",
       " '....',\n",
       " 'so',\n",
       " 'scuffles',\n",
       " ',',\n",
       " 'death',\n",
       " 'stares',\n",
       " ',',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'I',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " '.',\n",
       " 'Forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " ',',\n",
       " 'forget',\n",
       " 'charm',\n",
       " ',',\n",
       " 'forget',\n",
       " 'romance',\n",
       " '...',\n",
       " 'OZ',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'I',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal',\n",
       " ',',\n",
       " 'I',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'I',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'I',\n",
       " 'watched',\n",
       " 'more',\n",
       " ',',\n",
       " 'I',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'Oz',\n",
       " ',',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " '.',\n",
       " 'Not',\n",
       " 'just',\n",
       " 'violence',\n",
       " ',',\n",
       " 'but',\n",
       " 'injustice',\n",
       " '(',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel',\n",
       " ',',\n",
       " 'inmates',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'well',\n",
       " 'mannered',\n",
       " ',',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience',\n",
       " ')',\n",
       " 'Watching',\n",
       " 'Oz',\n",
       " ',',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " '....',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side',\n",
       " '.']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(sample_review)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5394e53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One',\n",
       " 'reviewers',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " '1',\n",
       " 'Oz',\n",
       " 'episode',\n",
       " \"'ll\",\n",
       " 'hooked',\n",
       " '.',\n",
       " 'right',\n",
       " ',',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'me.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'Oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'violence',\n",
       " ',',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'GO',\n",
       " '.',\n",
       " 'Trust',\n",
       " ',',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid',\n",
       " '.',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'punches',\n",
       " 'regards',\n",
       " 'drugs',\n",
       " ',',\n",
       " 'sex',\n",
       " 'violence',\n",
       " '.',\n",
       " 'hardcore',\n",
       " ',',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'called',\n",
       " 'OZ',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'Oswald',\n",
       " 'Maximum',\n",
       " 'Security',\n",
       " 'State',\n",
       " 'Penitentary',\n",
       " '.',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'Emerald',\n",
       " 'City',\n",
       " ',',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'face',\n",
       " 'inwards',\n",
       " ',',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda',\n",
       " '.',\n",
       " 'Em',\n",
       " 'City',\n",
       " 'home',\n",
       " 'many',\n",
       " '..',\n",
       " 'Aryans',\n",
       " ',',\n",
       " 'Muslims',\n",
       " ',',\n",
       " 'gangstas',\n",
       " ',',\n",
       " 'Latinos',\n",
       " ',',\n",
       " 'Christians',\n",
       " ',',\n",
       " 'Italians',\n",
       " ',',\n",
       " 'Irish',\n",
       " '....',\n",
       " 'scuffles',\n",
       " ',',\n",
       " 'death',\n",
       " 'stares',\n",
       " ',',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " '.',\n",
       " 'Forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " ',',\n",
       " 'forget',\n",
       " 'charm',\n",
       " ',',\n",
       " 'forget',\n",
       " 'romance',\n",
       " '...',\n",
       " 'OZ',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " '.',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " ',',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'ready',\n",
       " ',',\n",
       " 'watched',\n",
       " ',',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'Oz',\n",
       " ',',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " '.',\n",
       " 'violence',\n",
       " ',',\n",
       " 'injustice',\n",
       " '(',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " \"'ll\",\n",
       " 'sold',\n",
       " 'nickel',\n",
       " ',',\n",
       " 'inmates',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " ',',\n",
       " 'well',\n",
       " 'mannered',\n",
       " ',',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience',\n",
       " ')',\n",
       " 'Watching',\n",
       " 'Oz',\n",
       " ',',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " '....',\n",
       " 'thats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side',\n",
       " '.']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download(stopwords)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_token = [ word for word in tokens if word.lower()not in stop_words]\n",
    "filtered_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8f954f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'review',\n",
       " 'mention',\n",
       " 'watch',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episod',\n",
       " \"'ll\",\n",
       " 'hook',\n",
       " '.',\n",
       " 'right',\n",
       " ',',\n",
       " 'exactli',\n",
       " 'happen',\n",
       " 'me.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutal',\n",
       " 'unflinch',\n",
       " 'scene',\n",
       " 'violenc',\n",
       " ',',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " '.',\n",
       " 'trust',\n",
       " ',',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'heart',\n",
       " 'timid',\n",
       " '.',\n",
       " 'show',\n",
       " 'pull',\n",
       " 'punch',\n",
       " 'regard',\n",
       " 'drug',\n",
       " ',',\n",
       " 'sex',\n",
       " 'violenc',\n",
       " '.',\n",
       " 'hardcor',\n",
       " ',',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'call',\n",
       " 'oz',\n",
       " 'nicknam',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'secur',\n",
       " 'state',\n",
       " 'penitentari',\n",
       " '.',\n",
       " 'focus',\n",
       " 'mainli',\n",
       " 'emerald',\n",
       " 'citi',\n",
       " ',',\n",
       " 'experiment',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cell',\n",
       " 'glass',\n",
       " 'front',\n",
       " 'face',\n",
       " 'inward',\n",
       " ',',\n",
       " 'privaci',\n",
       " 'high',\n",
       " 'agenda',\n",
       " '.',\n",
       " 'em',\n",
       " 'citi',\n",
       " 'home',\n",
       " 'mani',\n",
       " '..',\n",
       " 'aryan',\n",
       " ',',\n",
       " 'muslim',\n",
       " ',',\n",
       " 'gangsta',\n",
       " ',',\n",
       " 'latino',\n",
       " ',',\n",
       " 'christian',\n",
       " ',',\n",
       " 'italian',\n",
       " ',',\n",
       " 'irish',\n",
       " '....',\n",
       " 'scuffl',\n",
       " ',',\n",
       " 'death',\n",
       " 'stare',\n",
       " ',',\n",
       " 'dodgi',\n",
       " 'deal',\n",
       " 'shadi',\n",
       " 'agreement',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goe',\n",
       " 'show',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " '.',\n",
       " 'forget',\n",
       " 'pretti',\n",
       " 'pictur',\n",
       " 'paint',\n",
       " 'mainstream',\n",
       " 'audienc',\n",
       " ',',\n",
       " 'forget',\n",
       " 'charm',\n",
       " ',',\n",
       " 'forget',\n",
       " 'romanc',\n",
       " '...',\n",
       " 'oz',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " '.',\n",
       " 'first',\n",
       " 'episod',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasti',\n",
       " 'surreal',\n",
       " ',',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'readi',\n",
       " ',',\n",
       " 'watch',\n",
       " ',',\n",
       " 'develop',\n",
       " 'tast',\n",
       " 'oz',\n",
       " ',',\n",
       " 'got',\n",
       " 'accustom',\n",
       " 'high',\n",
       " 'level',\n",
       " 'graphic',\n",
       " 'violenc',\n",
       " '.',\n",
       " 'violenc',\n",
       " ',',\n",
       " 'injustic',\n",
       " '(',\n",
       " 'crook',\n",
       " 'guard',\n",
       " \"'ll\",\n",
       " 'sold',\n",
       " 'nickel',\n",
       " ',',\n",
       " 'inmat',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " ',',\n",
       " 'well',\n",
       " 'manner',\n",
       " ',',\n",
       " 'middl',\n",
       " 'class',\n",
       " 'inmat',\n",
       " 'turn',\n",
       " 'prison',\n",
       " 'bitch',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skill',\n",
       " 'prison',\n",
       " 'experi',\n",
       " ')',\n",
       " 'watch',\n",
       " 'oz',\n",
       " ',',\n",
       " 'may',\n",
       " 'becom',\n",
       " 'comfort',\n",
       " 'uncomfort',\n",
       " 'view',\n",
       " '....',\n",
       " 'that',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side',\n",
       " '.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_token ]\n",
    "stemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bc82cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Laptop\n",
      "[nltk_data]     wala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Laptop wala/nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Laptop wala/nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\2997831838.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wordnet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlemmatizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlemmatizer_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_token\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mlemmatizer_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10768\\2997831838.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'wordnet'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlemmatizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mlemmatizer_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_token\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mlemmatizer_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\stem\\wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mlemma\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mword\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mlemmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__reader_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# This is where the magic happens!  Transform ourselves into\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, root, omw_reader)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             )\n\u001b[0;32m   1175\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprovenances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0momw_prov\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m         \u001b[1;31m# A cache to store the wordnet data of multiple languages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordnet.py\u001b[0m in \u001b[0;36momw_prov\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[0mprovdict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0mprovdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1285\u001b[1;33m         \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_omw_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1286\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfileid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m             \u001b[0mprov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlangfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# __class__ to something new:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[1;31m# Load the corpus.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\corpus\\util.py\u001b[0m in \u001b[0;36m__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"*\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m70\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Laptop wala/nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\share\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\anaconda3\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Laptop wala\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "#lemmatization\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer_words = [lemmatizer.lemmatize(word) for word in filtered_token]\n",
    "lemmatizer_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff168ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('One', 'CD'),\n",
       " ('reviewers', 'NNS'),\n",
       " ('mentioned', 'VBD'),\n",
       " ('watching', 'VBG'),\n",
       " ('1', 'CD'),\n",
       " ('Oz', 'NNP'),\n",
       " ('episode', 'NN'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('hooked', 'VB'),\n",
       " ('.', '.'),\n",
       " ('right', 'NN'),\n",
       " (',', ','),\n",
       " ('exactly', 'RB'),\n",
       " ('happened', 'VBD'),\n",
       " ('me.', 'JJ'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('first', 'JJ'),\n",
       " ('thing', 'NN'),\n",
       " ('struck', 'VBD'),\n",
       " ('Oz', 'NNP'),\n",
       " ('brutality', 'NN'),\n",
       " ('unflinching', 'VBG'),\n",
       " ('scenes', 'NNS'),\n",
       " ('violence', 'NN'),\n",
       " (',', ','),\n",
       " ('set', 'VBN'),\n",
       " ('right', 'NN'),\n",
       " ('word', 'NN'),\n",
       " ('GO', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('Trust', 'NNP'),\n",
       " (',', ','),\n",
       " ('show', 'VBP'),\n",
       " ('faint', 'NN'),\n",
       " ('hearted', 'VBN'),\n",
       " ('timid', 'NN'),\n",
       " ('.', '.'),\n",
       " ('show', 'NN'),\n",
       " ('pulls', 'VBZ'),\n",
       " ('punches', 'NNS'),\n",
       " ('regards', 'NNS'),\n",
       " ('drugs', 'NNS'),\n",
       " (',', ','),\n",
       " ('sex', 'NN'),\n",
       " ('violence', 'NN'),\n",
       " ('.', '.'),\n",
       " ('hardcore', 'NN'),\n",
       " (',', ','),\n",
       " ('classic', 'JJ'),\n",
       " ('use', 'NN'),\n",
       " ('word.', 'NN'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('called', 'VBD'),\n",
       " ('OZ', 'NNP'),\n",
       " ('nickname', 'NN'),\n",
       " ('given', 'VBN'),\n",
       " ('Oswald', 'NNP'),\n",
       " ('Maximum', 'NNP'),\n",
       " ('Security', 'NNP'),\n",
       " ('State', 'NNP'),\n",
       " ('Penitentary', 'NNP'),\n",
       " ('.', '.'),\n",
       " ('focuses', 'VBZ'),\n",
       " ('mainly', 'RB'),\n",
       " ('Emerald', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " (',', ','),\n",
       " ('experimental', 'JJ'),\n",
       " ('section', 'NN'),\n",
       " ('prison', 'NN'),\n",
       " ('cells', 'NNS'),\n",
       " ('glass', 'NN'),\n",
       " ('fronts', 'NNS'),\n",
       " ('face', 'VBP'),\n",
       " ('inwards', 'NNS'),\n",
       " (',', ','),\n",
       " ('privacy', 'NN'),\n",
       " ('high', 'JJ'),\n",
       " ('agenda', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Em', 'NNP'),\n",
       " ('City', 'NNP'),\n",
       " ('home', 'NN'),\n",
       " ('many', 'JJ'),\n",
       " ('..', 'NNP'),\n",
       " ('Aryans', 'NNPS'),\n",
       " (',', ','),\n",
       " ('Muslims', 'NNP'),\n",
       " (',', ','),\n",
       " ('gangstas', 'NN'),\n",
       " (',', ','),\n",
       " ('Latinos', 'NNP'),\n",
       " (',', ','),\n",
       " ('Christians', 'NNP'),\n",
       " (',', ','),\n",
       " ('Italians', 'NNP'),\n",
       " (',', ','),\n",
       " ('Irish', 'NNP'),\n",
       " ('....', 'NNP'),\n",
       " ('scuffles', 'NNS'),\n",
       " (',', ','),\n",
       " ('death', 'NN'),\n",
       " ('stares', 'NNS'),\n",
       " (',', ','),\n",
       " ('dodgy', 'JJ'),\n",
       " ('dealings', 'NNS'),\n",
       " ('shady', 'JJ'),\n",
       " ('agreements', 'NNS'),\n",
       " ('never', 'RB'),\n",
       " ('far', 'RB'),\n",
       " ('away.', 'JJ'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('br', 'NN'),\n",
       " ('/', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('would', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('main', 'JJ'),\n",
       " ('appeal', 'NN'),\n",
       " ('show', 'NN'),\n",
       " ('due', 'JJ'),\n",
       " ('fact', 'NN'),\n",
       " ('goes', 'VBZ'),\n",
       " ('shows', 'NNS'),\n",
       " ('would', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('dare', 'VB'),\n",
       " ('.', '.'),\n",
       " ('Forget', 'NNP'),\n",
       " ('pretty', 'JJ'),\n",
       " ('pictures', 'NNS'),\n",
       " ('painted', 'VBN'),\n",
       " ('mainstream', 'NN'),\n",
       " ('audiences', 'NNS'),\n",
       " (',', ','),\n",
       " ('forget', 'VB'),\n",
       " ('charm', 'NN'),\n",
       " (',', ','),\n",
       " ('forget', 'VB'),\n",
       " ('romance', 'NN'),\n",
       " ('...', ':'),\n",
       " ('OZ', 'VBP'),\n",
       " (\"n't\", 'RB'),\n",
       " ('mess', 'VB'),\n",
       " ('around', 'RB'),\n",
       " ('.', '.'),\n",
       " ('first', 'JJ'),\n",
       " ('episode', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('saw', 'VBD'),\n",
       " ('struck', 'JJ'),\n",
       " ('nasty', 'JJ'),\n",
       " ('surreal', 'NN'),\n",
       " (',', ','),\n",
       " ('could', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('say', 'VB'),\n",
       " ('ready', 'JJ'),\n",
       " (',', ','),\n",
       " ('watched', 'VBD'),\n",
       " (',', ','),\n",
       " ('developed', 'VBD'),\n",
       " ('taste', 'NN'),\n",
       " ('Oz', 'NNP'),\n",
       " (',', ','),\n",
       " ('got', 'VBD'),\n",
       " ('accustomed', 'VBN'),\n",
       " ('high', 'JJ'),\n",
       " ('levels', 'NNS'),\n",
       " ('graphic', 'JJ'),\n",
       " ('violence', 'NN'),\n",
       " ('.', '.'),\n",
       " ('violence', 'NN'),\n",
       " (',', ','),\n",
       " ('injustice', 'NN'),\n",
       " ('(', '('),\n",
       " ('crooked', 'JJ'),\n",
       " ('guards', 'NNS'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('sold', 'VB'),\n",
       " ('nickel', 'RB'),\n",
       " (',', ','),\n",
       " ('inmates', 'VBZ'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('kill', 'VB'),\n",
       " ('order', 'NN'),\n",
       " ('get', 'VB'),\n",
       " ('away', 'RB'),\n",
       " (',', ','),\n",
       " ('well', 'RB'),\n",
       " ('mannered', 'VBN'),\n",
       " (',', ','),\n",
       " ('middle', 'JJ'),\n",
       " ('class', 'NN'),\n",
       " ('inmates', 'NNS'),\n",
       " ('turned', 'VBD'),\n",
       " ('prison', 'NN'),\n",
       " ('bitches', 'NNS'),\n",
       " ('due', 'JJ'),\n",
       " ('lack', 'VBP'),\n",
       " ('street', 'NN'),\n",
       " ('skills', 'NNS'),\n",
       " ('prison', 'VBP'),\n",
       " ('experience', 'NN'),\n",
       " (')', ')'),\n",
       " ('Watching', 'NNP'),\n",
       " ('Oz', 'NNP'),\n",
       " (',', ','),\n",
       " ('may', 'MD'),\n",
       " ('become', 'VB'),\n",
       " ('comfortable', 'JJ'),\n",
       " ('uncomfortable', 'JJ'),\n",
       " ('viewing', 'VBG'),\n",
       " ('....', 'NN'),\n",
       " ('thats', 'NNS'),\n",
       " ('get', 'VBP'),\n",
       " ('touch', 'JJ'),\n",
       " ('darker', 'NN'),\n",
       " ('side', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tags = nltk.pos_tag(filtered_token)\n",
    "pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92e561",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
